{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch.distributed as dist\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import torch.utils.data\n",
    "import yaml\n",
    "from torch.cuda import amp\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "\n",
    "import test  # import test.py to get mAP after each epoch\n",
    "from models.yolo import Model\n",
    "from utils.datasets import create_dataloader\n",
    "from utils.general import (\n",
    "    torch_distributed_zero_first, labels_to_class_weights, plot_labels, check_anchors, labels_to_image_weights,\n",
    "    compute_loss, plot_images, fitness, strip_optimizer, plot_results, get_latest_run, check_dataset, check_file,\n",
    "    check_git_status, check_img_size, increment_dir, print_mutation, plot_evolution, set_logging, init_seeds,\n",
    "non_max_suppression)\n",
    "from utils.google_utils import attempt_download\n",
    "from utils.torch_utils import ModelEMA, select_device, intersect_dicts\n",
    "from utils.torch_utils import select_device, time_synchronized\n",
    "\n",
    "class AttrDict(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(AttrDict, self).__init__(*args, **kwargs)\n",
    "        self.__dict__ = self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "exp = 'runs/exp0'\n",
    "opt_ = check_file(f'{exp}/opt.yaml')\n",
    "weights = f'{exp}/weights/best.pt'\n",
    "nc, names = (1, ['coolingTower'])\n",
    "rank = -1\n",
    "device = torch.device('cpu')\n",
    "half = device.type != 'cpu' \n",
    "with open(opt_) as f:\n",
    "    opt = yaml.load(f, Loader=yaml.FullLoader)\n",
    "opt = AttrDict(opt)\n",
    "    \n",
    "    \n",
    "#Other params\n",
    "imgsz = opt['img_size'][0]\n",
    "batch_size = 1# opt['batch_size']\n",
    "conf_thres = 0.2\n",
    "iou_thres = 0.6\n",
    "\n",
    "with open(opt['hyp']) as f:\n",
    "    hyp = yaml.load(f, Loader=yaml.FullLoader)  # load hyps\n",
    "    if 'box' not in hyp:\n",
    "        warn('Compatibility: %s missing \"box\" which was renamed from \"giou\" in %s' %\n",
    "             (opt['hyp'], 'https://github.com/ultralytics/yolov5/pull/1120'))\n",
    "        hyp['box'] = hyp.pop('giou')\n",
    "pretrained = weights.endswith('.pt')\n",
    "if pretrained:\n",
    "    with torch_distributed_zero_first(rank):\n",
    "        attempt_download(weights)  # download if not found locally\n",
    "    ckpt = torch.load(weights, map_location=device)  # load checkpoint\n",
    "    if hyp.get('anchors'):\n",
    "        ckpt['model'].yaml['anchors'] = round(hyp['anchors'])  # force autoanchor\n",
    "    model = Model(opt['cfg'] or ckpt['model'].yaml, ch=3, nc=nc).to(device)  # create\n",
    "    exclude = ['anchor'] if opt['cfg'] or hyp.get('anchors') else []  # exclude keys\n",
    "    state_dict = ckpt['model'].float().state_dict()  # to FP32\n",
    "    state_dict = intersect_dicts(state_dict, model.state_dict(), exclude=exclude)  # intersect\n",
    "    model.load_state_dict(state_dict, strict=False)  # load\n",
    "else:\n",
    "    model = Model(opt['cfg'], ch=3, nc=nc).to(device)  # create\n",
    "\n",
    "iouv = torch.linspace(0.5, 0.95, 10).to(device)  # iou vector for mAP@0.5:0.95\n",
    "niou = iouv.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning labels ../datasets/coolingTowers128/labels/train.cache (471 found, 0 missing, 151 empty, 1 duplicate, for 622 images): 622it [00:00, 20550.76it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with open('data/coolingTowers128.yaml') as f:\n",
    "    data = yaml.load(f, Loader=yaml.FullLoader)  # model dict\n",
    "check_dataset(data)  # check\n",
    "\n",
    "img = torch.zeros((1, 3, imgsz, imgsz), device=device)  # init img\n",
    "_ = model(img.half() if half else img) if device.type != 'cpu' else None  # run once\n",
    "path = data['train']  # path to val/test images\n",
    "dataloader = create_dataloader(path, imgsz, batch_size, model.stride.max(), opt,\n",
    "                               hyp=None, augment=False, cache=False, pad=0.5, rect=True)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from numpy import random\n",
    "\n",
    "from models.experimental import attempt_load\n",
    "from utils.datasets import LoadStreams, LoadImages\n",
    "from utils.general import (\n",
    "    check_img_size, non_max_suppression, apply_classifier, scale_coords,\n",
    "    xyxy2xywh, plot_one_box, strip_optimizer, set_logging)\n",
    "from utils.torch_utils import select_device, load_classifier, time_synchronized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n"
     ]
    }
   ],
   "source": [
    "device = select_device('cpu')\n",
    "model = attempt_load('yolov5s.pt', map_location=device)\n",
    "imgsz = check_img_size(416, s=model.stride.max())\n",
    "t0 = time.time()\n",
    "img = torch.zeros((1, 3, imgsz, imgsz), device=device)  # init img\n",
    "_ = model(img.half() if half else img) if device.type != 'cpu' else None  # run once\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 1280, 3)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1/2 /home/martinesguerra/Documents/repos/yolov5/inference/images/bus.jpg: image 2/2 /home/martinesguerra/Documents/repos/yolov5/inference/images/zidane.jpg: "
     ]
    }
   ],
   "source": [
    "dataset = LoadImages('inference/images/')\n",
    "for path, img, im0, vid_cap in dataset:\n",
    "    img = torch.from_numpy(img).to(device)\n",
    "    half = False\n",
    "    img = img.half() if half else img.float()  # uint8 to fp16/32\n",
    "    img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
    "    if img.ndimension() == 3:\n",
    "        img = img.unsqueeze(0)\n",
    "\n",
    "    # Inference\n",
    "    t1 = time_synchronized()\n",
    "    pred = model(img, augment=False)[0]\n",
    "    pred = non_max_suppression(pred, agnostic=False, classes=None, iou_thres=0.45,conf_thres=0.4)\n",
    "    for i, det in enumerate(pred):\n",
    "        if det is not None and len(det):\n",
    "                    # Rescale boxes from img_size to im0 size\n",
    "                    det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7.47000e+02, 4.00000e+01, 1.15000e+03, 7.12000e+02, 8.68075e-01, 0.00000e+00],\n",
       "        [1.16000e+02, 1.97000e+02, 1.00300e+03, 7.12000e+02, 7.97377e-01, 0.00000e+00],\n",
       "        [4.24000e+02, 4.30000e+02, 5.17000e+02, 7.20000e+02, 7.78108e-01, 2.70000e+01]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "det"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
