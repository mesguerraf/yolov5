{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch.distributed as dist\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import torch.utils.data\n",
    "import yaml\n",
    "from torch.cuda import amp\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "\n",
    "import test  # import test.py to get mAP after each epoch\n",
    "from models.yolo import Model\n",
    "from utils.datasets import create_dataloader\n",
    "from utils.general import (\n",
    "    torch_distributed_zero_first, labels_to_class_weights, plot_labels, check_anchors, labels_to_image_weights,\n",
    "    compute_loss, plot_images, fitness, strip_optimizer, plot_results, get_latest_run, check_dataset, check_file,\n",
    "    check_git_status, check_img_size, increment_dir, print_mutation, plot_evolution, set_logging, init_seeds,\n",
    "non_max_suppression)\n",
    "from utils.google_utils import attempt_download\n",
    "from utils.torch_utils import ModelEMA, select_device, intersect_dicts\n",
    "from utils.torch_utils import select_device, time_synchronized\n",
    "\n",
    "class AttrDict(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(AttrDict, self).__init__(*args, **kwargs)\n",
    "        self.__dict__ = self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "exp = 'runs/exp0'\n",
    "opt_ = check_file(f'{exp}/opt.yaml')\n",
    "weights = f'{exp}/weights/best.pt'\n",
    "nc, names = (1, ['coolingTower'])\n",
    "rank = -1\n",
    "device = torch.device('cpu')\n",
    "half = device.type != 'cpu' \n",
    "with open(opt_) as f:\n",
    "    opt = yaml.load(f, Loader=yaml.FullLoader)\n",
    "opt = AttrDict(opt)\n",
    "    \n",
    "    \n",
    "#Other params\n",
    "imgsz = opt['img_size'][0]\n",
    "batch_size = 1# opt['batch_size']\n",
    "conf_thres = 0.2\n",
    "iou_thres = 0.6\n",
    "\n",
    "with open(opt['hyp']) as f:\n",
    "    hyp = yaml.load(f, Loader=yaml.FullLoader)  # load hyps\n",
    "    if 'box' not in hyp:\n",
    "        warn('Compatibility: %s missing \"box\" which was renamed from \"giou\" in %s' %\n",
    "             (opt['hyp'], 'https://github.com/ultralytics/yolov5/pull/1120'))\n",
    "        hyp['box'] = hyp.pop('giou')\n",
    "pretrained = weights.endswith('.pt')\n",
    "if pretrained:\n",
    "    with torch_distributed_zero_first(rank):\n",
    "        attempt_download(weights)  # download if not found locally\n",
    "    ckpt = torch.load(weights, map_location=device)  # load checkpoint\n",
    "    if hyp.get('anchors'):\n",
    "        ckpt['model'].yaml['anchors'] = round(hyp['anchors'])  # force autoanchor\n",
    "    model = Model(opt['cfg'] or ckpt['model'].yaml, ch=3, nc=nc).to(device)  # create\n",
    "    exclude = ['anchor'] if opt['cfg'] or hyp.get('anchors') else []  # exclude keys\n",
    "    state_dict = ckpt['model'].float().state_dict()  # to FP32\n",
    "    state_dict = intersect_dicts(state_dict, model.state_dict(), exclude=exclude)  # intersect\n",
    "    model.load_state_dict(state_dict, strict=False)  # load\n",
    "else:\n",
    "    model = Model(opt['cfg'], ch=3, nc=nc).to(device)  # create\n",
    "\n",
    "iouv = torch.linspace(0.5, 0.95, 10).to(device)  # iou vector for mAP@0.5:0.95\n",
    "niou = iouv.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning labels ../datasets/coolingTowers128/labels/train.cache (471 found, 0 missing, 151 empty, 1 duplicate, for 622 images): 622it [00:00, 20550.76it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with open('data/coolingTowers128.yaml') as f:\n",
    "    data = yaml.load(f, Loader=yaml.FullLoader)  # model dict\n",
    "check_dataset(data)  # check\n",
    "\n",
    "img = torch.zeros((1, 3, imgsz, imgsz), device=device)  # init img\n",
    "_ = model(img.half() if half else img) if device.type != 'cpu' else None  # run once\n",
    "path = data['train']  # path to val/test images\n",
    "dataloader = create_dataloader(path, imgsz, batch_size, model.stride.max(), opt,\n",
    "                               hyp=None, augment=False, cache=False, pad=0.5, rect=True)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95:   0%|          | 0/622 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'save_txt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-29db9784913f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# Append to text file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0msave_txt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0mgn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# normalization gain whwh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'save_txt' is not defined"
     ]
    }
   ],
   "source": [
    "s = ('%20s' + '%12s' * 6) % ('Class', 'Images', 'Targets', 'P', 'R', 'mAP@.5', 'mAP@.5:.95')\n",
    "p, r, f1, mp, mr, map50, map, t0, t1 = 0., 0., 0., 0., 0., 0., 0., 0., 0.\n",
    "loss = torch.zeros(3, device=device)\n",
    "jdict, stats, ap, ap_class = [], [], [], []\n",
    "seen = 0\n",
    "\n",
    "for batch_i, (img, targets, paths, shapes) in enumerate(tqdm(dataloader, desc=s)):\n",
    "    img = img.to(device, non_blocking=True)\n",
    "    img = img.half() if half else img.float()  # uint8 to fp16/32\n",
    "    img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
    "    targets = targets.to(device)\n",
    "    nb, _, height, width = img.shape  # batch size, channels, height, width\n",
    "    whwh = torch.Tensor([width, height, width, height]).to(device)\n",
    "\n",
    "    # Disable gradients\n",
    "    with torch.no_grad():\n",
    "        # Run model\n",
    "        t = time_synchronized()\n",
    "        inf_out, train_out = model(img, augment=True)  # inference and training outputs\n",
    "        t0 += time_synchronized() - t\n",
    "\n",
    "        # Compute loss\n",
    "        \n",
    "        # Run NMS\n",
    "        t = time_synchronized()\n",
    "        output = non_max_suppression(inf_out, conf_thres=conf_thres, iou_thres=iou_thres)\n",
    "        t1 += time_synchronized() - t\n",
    "\n",
    "    # Statistics per image\n",
    "    for si, pred in enumerate(output):\n",
    "        labels = targets[targets[:, 0] == si, 1:]\n",
    "        nl = len(labels)\n",
    "        tcls = labels[:, 0].tolist() if nl else []  # target class\n",
    "        seen += 1\n",
    "\n",
    "        if pred is None:\n",
    "            if nl:\n",
    "                stats.append((torch.zeros(0, niou, dtype=torch.bool), torch.Tensor(), torch.Tensor(), tcls))\n",
    "            continue\n",
    "\n",
    "        # Append to text file\n",
    "        if save_txt:\n",
    "            gn = torch.tensor(shapes[si][0])[[1, 0, 1, 0]]  # normalization gain whwh\n",
    "            x = pred.clone()\n",
    "            x[:, :4] = scale_coords(img[si].shape[1:], x[:, :4], shapes[si][0], shapes[si][1])  # to original\n",
    "            for *xyxy, conf, cls in x:\n",
    "                xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh\n",
    "                line = (cls, conf, *xywh) if save_conf else (cls, *xywh)  # label format\n",
    "                with open(str(out / Path(paths[si]).stem) + '.txt', 'a') as f:\n",
    "                    f.write(('%g ' * len(line) + '\\n') % line)\n",
    "\n",
    "        # Clip boxes to image bounds\n",
    "        clip_coords(pred, (height, width))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.56974e+02, 3.89185e+02, 4.94372e+02, 5.19322e+02, 3.43784e-01, 0.00000e+00]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
